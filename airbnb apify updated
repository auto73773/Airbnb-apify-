from datetime import datetime, timedelta
import requests
import json
import logging
import pandas as pd
from fake_useragent import UserAgent
import apify
from urllib.parse import urlparse
import base64

# Function to encode room ID to base64
def encode_to_base64(room_id):
    encoded = base64.b64encode(room_id.encode('utf-8')).decode('utf-8')
    return encoded

# Function to generate dynamic check-in and check-out dates for a given number of days
def dynamic_date_generator(start_date, number_of_days, difference_between_days):
    """
    Generate a sequence of check-in and check-out dates based on the number of days.
    Each call yields a new pair of dates.
    """
    current_date = datetime.strptime(start_date, '%Y-%m-%d')
    number_of_days = int(number_of_days) 
    for _ in range(number_of_days):
        check_in = current_date
        check_out = check_in + timedelta(days=difference_between_days)  # Check-out is 1 day after check-in
        yield check_in.strftime('%Y-%m-%d'), check_out.strftime('%Y-%m-%d')
        current_date += timedelta(days=1)

# Apify main function
async def main():
    await apify.Actor.init()  # Initialize the Apify actor before any other operations

    input_data = await apify.Actor.get_input()  # Get input from Apify
    links = input_data.get("startUrls")  # List of URLs
    check_in_date = input_data.get("checkInDate", "2024-11-21")
    difference_between_days = input_data.get("differenceBetweenCheckInCheckOut", 60)  # Default number of days to generate

    number_of_days = input_data.get("numberOfDays", 60)  # Default number of days to generate
    adults = input_data.get("adults", "2")
    children = input_data.get("children", "0")
    pets = input_data.get("pets", "0")

    data_list = []
    ua = UserAgent()

    def get_value(data, path):
        keys = path.replace("[", ".").replace("]", "").split(".")
        for key in keys:
            if isinstance(data, list):
                key = int(key)
            try:
                data = data[key]
            except (KeyError, IndexError, TypeError):
                return None
        return data

    async def store_data_in_apify_dataset(data):
        try:
            await apify.Actor.push_data(data)
            logging.info("Data pushed to Apify dataset successfully.")
        except Exception as e:
            logging.error(f"Error pushing data to Apify dataset: {e}")
   
    async def fetch_data(link, check_in_date, check_out_date):
        print(f"Processing link: {link} | Check-In: {check_in_date}, Check-Out: {check_out_date}")

        parsed_url = urlparse(link['url'])

        room_id = parsed_url.path.split('/')[-1]
        permanent = "StayListing"
        room_id = f"{permanent}:{room_id}"

        encoded_id = encode_to_base64(room_id)
        print(encoded_id)
        variables = {
            "id": encoded_id,
            "pdpSectionsRequest": {
                "adults": adults,
                "amenityFilters": None,
                "bypassTargetings": False,
                "children": children,
                "checkIn": check_in_date,
                "checkOut": check_out_date,
                "pets": pets,
                "layouts": ["SIDEBAR", "SINGLE_COLUMN"],
                "sectionIds": [
                    "BOOK_IT_CALENDAR_SHEET", "CANCELLATION_POLICY_PICKER_MODAL",
                    "POLICIES_DEFAULT", "BOOK_IT_SIDEBAR", "URGENCY_COMMITMENT_SIDEBAR",
                    "BOOK_IT_NAV", "MESSAGE_BANNER", "HIGHLIGHTS_DEFAULT",
                    "BOOK_IT_FLOATING_FOOTER", "EDUCATION_FOOTER_BANNER",
                    "URGENCY_COMMITMENT", "EDUCATION_FOOTER_BANNER_MODAL"
                ]
            }
        }

        params = {
            'operationName': 'StaysPdpSections',
            'locale': 'en-USD',
            'currency': 'USD',
            'variables': json.dumps(variables),
            'extensions': '{"persistedQuery":{"version":1,"sha256Hash":"38218432c2d53194baa9c592ddd8e664cffcbcac58f0e118e8c1680eb9d58da7"}}'
        }

        headers = {
            'accept': '*/*',
            'accept-language': 'en-US,en;q=0.9',
            'cache-control': 'no-cache',
            'content-type': 'application/json',
            'user-agent': ua.random,
            'x-airbnb-api-key': 'd306zoyjsyarp7ifhu67rjxn52tv0t20',
            'x-csrf-without-token': '1',
            'x-requested-with': 'XMLHttpRequest'
        }

        try:
            url = 'https://www.airbnb.co.uk/api/v3/StaysPdpSections/38218432c2d53194baa9c592ddd8e664cffcbcac58f0e118e8c1680eb9d58da7'

            response = requests.get(url, params=params, headers=headers)
            response.raise_for_status()

            response_json = response.json()

            # Extract SEO Data
            seo_paths = {
                "Title": "data.presentation.stayProductDetailPage.sections.metadata.seoFeatures.title",
                "Meta Description": "data.presentation.stayProductDetailPage.sections.metadata.seoFeatures.metaDescription",
                "Canonical URL": "data.presentation.stayProductDetailPage.sections.metadata.seoFeatures.canonicalUrl",
                "Room Info": "data.presentation.stayProductDetailPage.sections.metadata.sharingConfig.title",
                "Property Type": "data.presentation.stayProductDetailPage.sections.metadata.sharingConfig.propertyType",
                "Room Rating": "data.presentation.stayProductDetailPage.sections.metadata.sharingConfig.starRating",  # e.g., 158 reviews

                "Total Reviews": "data.presentation.stayProductDetailPage.reviewCount",
                "Location": "data.presentation.stayProductDetailPage.sections.metadata.sharingConfig.location",
                "Capacity": "data.presentation.stayProductDetailPage.sections.metadata.sharingConfig.personCapacity",
                "Image URL": "data.presentation.stayProductDetailPage.sections.metadata.sharingConfig.imageUrl"
            }

            seo_data = {key: get_value(response_json, path) for key, path in seo_paths.items()}

            bar_price_data = response_json["data"]["presentation"]["stayProductDetailPage"]["sections"]["metadata"]["bookingPrefetchData"]["barPrice"]

            bar_price_details = {
                "Price Breakdown Title": get_value(bar_price_data, "explanationData.title"),
                "Price Breakdown Subtitle": get_value(bar_price_data, "explanationData.subtitle.legalDisclaimerSubtitle"),
                "Accessibility Label": bar_price_data.get("accessibilityLabel"),
                "Strike Through Price": get_value(bar_price_data, "displayPrices[0].priceString"),
                "Primary Price": get_value(bar_price_data, "displayPrices[1].priceString"),
                "Cleaning Fee": get_value(bar_price_data, "explanationData.priceGroups[0].items[1].priceString"),
                "Service Fee": get_value(bar_price_data, "explanationData.priceGroups[0].items[2].priceString"),
                "Taxes": get_value(bar_price_data, "explanationData.priceGroups[0].items[3].priceString"),
                "Total Price": get_value(bar_price_data, "explanationData.priceGroups[1].items[0].priceString"),
            }

            merged_data = {"Check-In Date": check_in_date, "Check-Out Date": check_out_date, **seo_data, **bar_price_details}

            # Store data in list for final output
            data_list.append(merged_data)

            print(f"Data fetched successfully for {link} | Check-In: {check_in_date}, Check-Out: {check_out_date}")

            # Pushing to Apify Dataset
            await store_data_in_apify_dataset(merged_data)

        except Exception as e:
            logging.error(f"Error fetching data for {link}: {e}")
            pass  # Log errors and continue

    # Iterating over each URL and calling fetch_data() function
    for link in links:
        for check_in_date, check_out_date in dynamic_date_generator(check_in_date, number_of_days, difference_between_days):
            await fetch_data(link, check_in_date, check_out_date)
    
    # Convert data_list to DataFrame for further processing or exporting
    df = pd.DataFrame(data_list)

# Set option to display all rows
    pd.set_option('display.max_rows', None)

    # Print the DataFrame
    print(df)

# Optionally, reset the display setting after
# pd.reset_option('display.max_rows')
